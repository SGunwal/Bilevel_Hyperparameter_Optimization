{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"n8SHwnndmBE7"},"outputs":[],"source":["#pip install scikit-optimize\n","!pip install -q -U keras-tuner\n","# !pip install hyperopt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zd0LXjRF_vxI"},"outputs":[],"source":["import os\n","import math\n","import numpy as np\n","import tensorflow as tf\n","import keras_tuner as kt\n","import tensorflow_datasets as tfds\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn import preprocessing\n","from keras.utils.np_utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.random import sample_without_replacement\n","from sklearn.utils import resample\n","from tensorflow.tools.docs import doc_controls\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yI4NMLPlE-v"},"outputs":[],"source":["train_dataset = np.load('train_dataset_10k_60.npz')\n","val_dataset = np.load('validation_dataset_10k_40.npz')\n","test_dataset = np.load('test_dataset.npz')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed17iWtTp8k8"},"outputs":[],"source":["# Preprocess the data (these are NumPy arrays)\n","x_train = train_dataset['x'].reshape(6000, 784).astype(\"float32\") / 255\n","x_test = test_dataset['x'].reshape(10010, 784).astype(\"float32\") / 255\n","y_train = train_dataset['y'].astype(\"float32\")\n","y_test = test_dataset['y'].astype(\"float32\")\n","x_val = val_dataset['x'].reshape(4000, 784).astype(\"float32\") / 255\n","y_val = val_dataset['y'].astype(\"float32\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ar3ppnzjPto0"},"outputs":[],"source":["# lamdas = kt.Float(\"l2\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","# print(lamdas)\n","# hp = kt.HyperParameters()\n","# print(hp.Int(\"units\", min_value=32, max_value=512, step=32))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCR3v2oReyUy"},"outputs":[],"source":["class CustomLoss(keras.losses.Loss):\n","    def __init__(self,model, lamda1, lamda2, name=\"custom_loss\"):\n","        super().__init__(name=name)\n","        # print(lamda)\n","        self.regularization_factor1 = tf.math.exp(lamda1)\n","        self.regularization_factor2 = tf.math.exp(lamda2)\n","        self.w1 = model.layers[1].weights[0]\n","        self.w2 = model.layers[2].weights[0]\n","\n","\n","    def call(self, y_true, y_pred):\n","        scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        loss = scce(y_true, y_pred)\n","        reg = self.regularization_factor1*tf.nn.l2_loss(self.w1) + self.regularization_factor2*tf.nn.l2_loss(self.w2)\n","        return loss + reg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffoaXnSxqCcU"},"outputs":[],"source":["def build_model(hp):\n","  # temp\n","  lamda1 = hp.Float(\"lamda1\", min_value=-10, max_value=-0.1,step=0.01)\n","  lamda2 = hp.Float(\"lamda2\", min_value=-10, max_value=-0.1,step=0.01)\n","  model = tf.keras.Sequential([\n","      tf.keras.layers.Flatten(input_shape=(784,)),\n","      tf.keras.layers.Dense(100 ,activation='relu'),#,kernel_regularizer='l2'),\n","      tf.keras.layers.Dense(10)#,kernel_regularizer='l2')#,kernel_regularizer=keras.regularizers.l2())    # didn't use softmax since it will be called when (logits=true) in below step\n","  ])\n","  l_rate = hp.Float(\"l_rate\", min_value=0.1,max_value=0.9,step = 0.01)\n","  momentum = hp.Float(\"momentum\", min_value=0.01,max_value=0.1,step = 0.01)\n","  optimizer = keras.optimizers.SGD(learning_rate=l_rate,momentum = momentum )\n","  lamda1 = tf.cast(lamda1,dtype='float32')\n","  lamda2 = tf.cast(lamda2,dtype='float32')\n","  model.compile(optimizer=optimizer, loss=CustomLoss(model,lamda1,lamda2),metrics=[tf.keras.metrics.SparseCategoricalCrossentropy(from_logits=True)])\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB6ClgyWTXX5"},"outputs":[],"source":["# print(lamda1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jg5M2EJII4wO","outputId":"a5a6079c-a450-470b-da01-40c6f74442f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 100 Complete [00h 00m 56s]\n","val_sparse_categorical_crossentropy: 0.1335955709218979\n","\n","Best val_sparse_categorical_crossentropy So Far: 0.13315953314304352\n","Total elapsed time: 01h 37m 22s\n","INFO:tensorflow:Oracle triggered exit\n","Search space summary\n","Default search space size: 4\n","lamda1 (Float)\n","{'default': -10.0, 'conditions': [], 'min_value': -10.0, 'max_value': -0.1, 'step': 0.01, 'sampling': None}\n","lamda2 (Float)\n","{'default': -10.0, 'conditions': [], 'min_value': -10.0, 'max_value': -0.1, 'step': 0.01, 'sampling': None}\n","l_rate (Float)\n","{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.9, 'step': 0.01, 'sampling': None}\n","momentum (Float)\n","{'default': 0.01, 'conditions': [], 'min_value': 0.01, 'max_value': 0.1, 'step': 0.01, 'sampling': None}\n"]}],"source":["tuner = kt.BayesianOptimization(build_model,objective=kt.Objective(\"val_sparse_categorical_crossentropy\",direction=\"min\"),max_trials=100,overwrite=True)\n","tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val))\n","tuner.search_space_summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iJW-nlMkOnH"},"outputs":[],"source":["models = tuner.get_best_models(num_models=1)   #get the best model\n","best_model = models[0]\n","# print(best_model.layers[1].get_weights())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRtjOECbIFFI","outputId":"67be680d-cecc-41bf-a3c8-07d026ee7d85"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------------optimal hyperparameters----------------------------\n","Optimal l_rate = 0.30999999999999994\n","Optimal momentum = 0.01\n","Optimal lamda1 = -6.920000000000066\n","Optimal lamda2 = -10.0\n"]}],"source":["best_hps = tuner.get_best_hyperparameters(1)\n","print('-----------------------optimal hyperparameters----------------------------')\n","\n","print(f'Optimal l_rate = {best_hps[0].get(\"l_rate\")}')\n","print(f'Optimal momentum = {best_hps[0].get(\"momentum\")}')\n","print(f'Optimal lamda1 = {best_hps[0].get(\"lamda1\")}')\n","print(f'Optimal lamda2 = {best_hps[0].get(\"lamda2\")}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64pfoNPAHw1h"},"outputs":[],"source":["def calculate_loss(X,Y,name):\n","  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","  logits = best_model(X)\n","  loss = loss_fn(Y,logits)\n","  print(f'{name}_loss = {loss}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5ehlcxhUiFa","outputId":"9be86cf6-07e3-4aad-c758-a86ea31fc6df"},"outputs":[{"name":"stdout","output_type":"stream","text":["validation_loss = 0.13315953314304352\n","training_loss = 0.00886882096529007\n","test_loss = 0.17881833016872406\n"]}],"source":["calculate_loss(x_val,y_val,\"validation\")\n","calculate_loss(x_train,y_train,\"training\")\n","calculate_loss(x_test,y_test,\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pee8Zy6FPnNa"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Testing_SMBO_10k_60_40(2HP).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}